{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in ./.local/lib/python2.7/site-packages (0.8.1)\n",
      "Requirement already satisfied: tqdm in ./.local/lib/python2.7/site-packages (4.23.4)\n",
      "Requirement already satisfied: kaggle in ./.local/lib/python2.7/site-packages (1.3.11.1)\n",
      "Requirement already satisfied: librosa in ./.local/lib/python2.7/site-packages (0.6.1)\n",
      "Collecting keras\n",
      "  Using cached https://files.pythonhosted.org/packages/68/12/4cabc5c01451eb3b413d19ea151f36e33026fc0efb932bf51bcaf54acbf5/Keras-2.2.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: requests in ./.local/lib/python2.7/site-packages (from kaggle) (2.19.0)\n",
      "Requirement already satisfied: urllib3<1.23.0,>=1.15 in ./.local/lib/python2.7/site-packages (from kaggle) (1.22)\n",
      "Requirement already satisfied: python-dateutil in ./.local/lib/python2.7/site-packages (from kaggle) (2.7.3)\n",
      "Requirement already satisfied: six>=1.10 in ./.local/lib/python2.7/site-packages (from kaggle) (1.11.0)\n",
      "Requirement already satisfied: certifi in ./.local/lib/python2.7/site-packages (from kaggle) (2018.4.16)\n",
      "Requirement already satisfied: joblib>=0.7.0 in ./.local/lib/python2.7/site-packages (from librosa) (0.11)\n",
      "Requirement already satisfied: scipy>=0.14.0 in ./.local/lib/python2.7/site-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.8.0 in ./.local/lib/python2.7/site-packages (from librosa) (1.14.4)\n",
      "Requirement already satisfied: resampy>=0.2.0 in ./.local/lib/python2.7/site-packages (from librosa) (0.2.1)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in ./.local/lib/python2.7/site-packages (from librosa) (0.19.1)\n",
      "Requirement already satisfied: decorator>=3.0.0 in ./.local/lib/python2.7/site-packages (from librosa) (4.3.0)\n",
      "Requirement already satisfied: numba>=0.38.0 in ./.local/lib/python2.7/site-packages (from librosa) (0.38.1)\n",
      "Requirement already satisfied: audioread>=2.0.0 in ./.local/lib/python2.7/site-packages (from librosa) (2.1.6)\n",
      "Requirement already satisfied: h5py in ./.local/lib/python2.7/site-packages (from keras) (2.8.0)\n",
      "Requirement already satisfied: pyyaml in ./.local/lib/python2.7/site-packages (from keras) (3.12)\n",
      "Requirement already satisfied: keras-preprocessing==1.0.1 in ./.local/lib/python2.7/site-packages (from keras) (1.0.1)\n",
      "Requirement already satisfied: keras-applications==1.0.2 in ./.local/lib/python2.7/site-packages (from keras) (1.0.2)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in ./.local/lib/python2.7/site-packages (from requests->kaggle) (2.7)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in ./.local/lib/python2.7/site-packages (from requests->kaggle) (3.0.4)\n",
      "Requirement already satisfied: llvmlite>=0.23.0dev0 in ./.local/lib/python2.7/site-packages (from numba>=0.38.0->librosa) (0.23.2)\n",
      "Requirement already satisfied: singledispatch in ./.local/lib/python2.7/site-packages (from numba>=0.38.0->librosa) (3.4.0.3)\n",
      "Requirement already satisfied: enum34 in ./.local/lib/python2.7/site-packages (from numba>=0.38.0->librosa) (1.1.6)\n",
      "Requirement already satisfied: funcsigs in ./.local/lib/python2.7/site-packages (from numba>=0.38.0->librosa) (1.0.2)\n",
      "\u001b[31mtensorflow-tensorboard 0.4.0 has requirement bleach==1.5.0, but you'll have bleach 2.1.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mtensorflow-tensorboard 0.4.0 has requirement html5lib==0.9999999, but you'll have html5lib 1.0.1 which is incompatible.\u001b[0m\n",
      "Installing collected packages: keras\n",
      "\u001b[31mCould not install packages due to an EnvironmentError: [Errno 13] Permission denied: '/usr/local/lib/python2.7/dist-packages/Keras-2.2.0.dist-info'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! python -m pip install seaborn tqdm kaggle librosa keras\n",
    "! wget -q https://raw.githubusercontent.com/m12sl/kaggle-freesound/master/utils.py -O utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "No module named keras",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-16225f47f93a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrelu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m from keras.callbacks import (\n",
      "\u001b[0;31mImportError\u001b[0m: No module named keras"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1001)\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import IPython\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "import IPython.display as ipd  # To play sound in the notebook\n",
    "import wave\n",
    "from scipy.io import wavfile\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import scipy\n",
    "from keras import losses, models, optimizers\n",
    "from keras.activations import relu, softmax\n",
    "from keras.callbacks import (\n",
    "    EarlyStopping, LearningRateScheduler, ModelCheckpoint, TensorBoard, ReduceLROnPlateau)\n",
    "from keras.layers import (\n",
    "    Convolution1D, Dense, Dropout, GlobalAveragePooling1D, GlobalMaxPool1D, Input, MaxPool1D, concatenate)\n",
    "from keras.utils import Sequence, to_categorical\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "\n",
    "\n",
    "import utils\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "COMPLETE_RUN = True\n",
    "\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # закомментируйте на время отладки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сначала проверьте пути\n",
    "\n",
    "DATADIR='/data/kaggle-freesound/'\n",
    "OUTDIR = './runs/'\n",
    "\n",
    "try:\n",
    "    os.makedirs(OUTDIR)\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "def get_audio(name, folder='audio_train'):\n",
    "    return os.path.join(DATADIR, folder, name)\n",
    "\n",
    "def get_path(name, folders=None):\n",
    "    folders = list(folders or [])\n",
    "    folders.append(name)\n",
    "    return os.path.join(DATADIR, *folders)\n",
    "\n",
    "\n",
    "AUDIO_TRAIN = get_path('audio_train')\n",
    "AUDIO_TEST = get_path('audio_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачиваем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_data = False\n",
    "\n",
    "if download_data:\n",
    "    token = ''\n",
    "    if not token and not os.path.exists(\"/home/ubuntu/.kaggle/kaggle.json\"):\n",
    "        raise ValueError('token not found')\n",
    "    if token:\n",
    "        ! echo $token > /home/ubuntu/.kaggle/kaggle.json\n",
    "        ! chmod 600 /home/ubuntu/.kaggle/kaggle.json\n",
    "\n",
    "    ! kaggle competitions download -c freesound-audio-tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if download_data:\n",
    "    ! rm -rf $DATADIR\n",
    "    ! cp \"/home/ubuntu/.kaggle/competitions/freesound-audio-tagging\" $DATADIR -rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip(src, dst=None):\n",
    "    print(\"Unzip:\", src)\n",
    "    if dst is None:\n",
    "        dst = os.path.dirname(src)\n",
    "    with zipfile.ZipFile(src, 'r') as archieve:\n",
    "        archieve.extractall(dst)\n",
    "\n",
    "if download_data:\n",
    "    unzip(os.path.join(DATADIR, \"audio_train.zip\"))\n",
    "    unzip(os.path.join(DATADIR, \"audio_test.zip\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls $DATADIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join(DATADIR, \"train.csv\"))\n",
    "test = pd.read_csv(os.path.join(DATADIR, \"sample_submission.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of training examples=\", train.shape[0], \"  Number of classes=\", len(train.label.unique()))\n",
    "print(train.label.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_group = train.groupby(['label', 'manually_verified']).count()\n",
    "plot = (\n",
    "    category_group.unstack()\n",
    "    .reindex(\n",
    "        category_group\n",
    "        .unstack()\n",
    "        .sum(axis=1)\n",
    "        .sort_values()\n",
    "        .index)\n",
    "    .plot(kind='bar', stacked=True, title=\"Number of Audio Samples per Category\", figsize=(16,10)))\n",
    "plot.set_xlabel(\"Category\")\n",
    "plot.set_ylabel(\"Number of Samples\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Minimum samples per category = ', min(train.label.value_counts()))\n",
    "print('Maximum samples per category = ', max(train.label.value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = get_audio('00044347.wav')   # Hi-hat\n",
    "display(ipd.Audio(fname))\n",
    "wav = wave.open(fname)\n",
    "print(\"Sampling (frame) rate = \", wav.getframerate())\n",
    "print(\"Total samples (frames) = \", wav.getnframes())\n",
    "print(\"Duration = \", wav.getnframes()/wav.getframerate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate, data = wavfile.read(fname)\n",
    "print(\"Sampling (frame) rate = \", rate)\n",
    "print(\"Total samples (frames) = \", data.shape)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(data, '-', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's zoom in on first 1000 frames\n",
    "\n",
    "plt.figure(figsize=(16, 4))\n",
    "plt.plot(data[:500], '.'); plt.plot(data[:500], '-');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Length\n",
    "\n",
    "We shall now analyze the lengths of the audio files in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['nframes'] = train['fname'].apply(lambda f: wave.open(get_audio(f)).getnframes())\n",
    "test['nframes'] = test['fname'].apply(lambda f: wave.open(get_audio(f, 'audio_test')).getnframes())\n",
    "\n",
    "_, ax = plt.subplots(figsize=(16, 4))\n",
    "sns.violinplot(ax=ax, x=\"label\", y=\"nframes\", data=train)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Distribution of audio frames, per label', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(figsize=(16, 4))\n",
    "sns.violinplot(ax=ax, x=\"label\", y=\"nframes\", data=test)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Distribution of audio frames, per label', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16,5))\n",
    "train.nframes.hist(bins=100, ax=axes[0])\n",
    "test.nframes.hist(bins=100, ax=axes[1])\n",
    "plt.suptitle('Frame Length Distribution in Train and Test', ha='center', fontsize='large');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe:\n",
    "\n",
    "    Majority of the audio files are short.\n",
    "    There are four abnormal length in the test histogram. Let's analyze them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "abnormal_length = [707364, 353682, 138474, 184338]\n",
    "\n",
    "for length in abnormal_length:\n",
    "    abnormal_fnames = test.loc[test.nframes == length, 'fname'].values\n",
    "    print(\"Frame length = \", length, \" Number of files = \", abnormal_fnames.shape[0], end=\"   \")\n",
    "    fname = np.random.choice(abnormal_fnames)\n",
    "    print(\"Playing \", fname)\n",
    "    IPython.display.display(ipd.Audio(get_audio(fname, 'audio_test')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    def __init__(self,\n",
    "                 sampling_rate=16000, audio_duration=2, n_classes=41,\n",
    "                 use_mfcc=False, n_folds=10, learning_rate=0.0001, \n",
    "                 max_epochs=50, n_mfcc=20):\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.audio_duration = audio_duration\n",
    "        self.n_classes = n_classes\n",
    "        self.use_mfcc = use_mfcc\n",
    "        self.n_mfcc = n_mfcc\n",
    "        self.n_folds = n_folds\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_epochs = max_epochs\n",
    "\n",
    "        self.audio_length = self.sampling_rate * self.audio_duration\n",
    "        if self.use_mfcc:\n",
    "            self.dim = (self.n_mfcc, 1 + int(np.floor(self.audio_length/512)), 1)\n",
    "        else:\n",
    "            self.dim = (self.audio_length, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, config, data_dir, list_IDs, labels=None, \n",
    "                 batch_size=64, preprocessing_fn=lambda x: x):\n",
    "        self.config = config\n",
    "        self.data_dir = data_dir\n",
    "        self.list_IDs = list_IDs\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.preprocessing_fn = preprocessing_fn\n",
    "        self.on_epoch_end()\n",
    "        self.dim = self.config.dim\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "        return self.__data_generation(list_IDs_temp)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        cur_batch_size = len(list_IDs_temp)\n",
    "        \n",
    "        X = np.empty(([cur_batch_size] + list(self.dim)))\n",
    "\n",
    "        input_length = self.config.audio_length\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            file_path = self.data_dir + ID\n",
    "            \n",
    "            # Read and Resample the audio\n",
    "            data, _ = librosa.core.load(file_path, sr=self.config.sampling_rate,\n",
    "                                        res_type='kaiser_fast')\n",
    "\n",
    "            # Random offset / Padding\n",
    "            if len(data) > input_length:\n",
    "                max_offset = len(data) - input_length\n",
    "                offset = np.random.randint(max_offset)\n",
    "                data = data[offset:(input_length+offset)]\n",
    "            else:\n",
    "                if input_length > len(data):\n",
    "                    max_offset = input_length - len(data)\n",
    "                    offset = np.random.randint(max_offset)\n",
    "                else:\n",
    "                    offset = 0\n",
    "                data = np.pad(data, (offset, input_length - len(data) - offset), \"constant\")\n",
    "                \n",
    "            # Normalization + Other Preprocessing\n",
    "            if self.config.use_mfcc:\n",
    "                data = librosa.feature.mfcc(data, sr=self.config.sampling_rate,\n",
    "                                                   n_mfcc=self.config.n_mfcc)\n",
    "                data = np.expand_dims(data, axis=-1)\n",
    "            else:\n",
    "                data = self.preprocessing_fn(data)[:, np.newaxis]\n",
    "            X[i,] = data\n",
    "\n",
    "        if self.labels is not None:\n",
    "            y = np.empty(cur_batch_size, dtype=int)\n",
    "            for i, ID in enumerate(list_IDs_temp):\n",
    "                y[i] = self.labels[ID]\n",
    "            return X, to_categorical(y, num_classes=self.config.n_classes)\n",
    "        else:\n",
    "            return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_norm(data):\n",
    "    max_data = np.max(data)\n",
    "    min_data = np.min(data)\n",
    "    data = (data-min_data)/(max_data-min_data+1e-6)\n",
    "    return data-0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_1d_dummy_model(config):\n",
    "    \n",
    "    nclass = config.n_classes\n",
    "    input_length = config.audio_length\n",
    "    \n",
    "    inp = Input(shape=(input_length,1))\n",
    "    x = GlobalMaxPool1D()(inp)\n",
    "    out = Dense(nclass, activation=softmax)(x)\n",
    "\n",
    "    model = models.Model(inputs=inp, outputs=out)\n",
    "    opt = optimizers.Adam(config.learning_rate)\n",
    "\n",
    "    model.compile(optimizer=opt, loss=losses.categorical_crossentropy, metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "def get_1d_conv_model(config):\n",
    "    \n",
    "    nclass = config.n_classes\n",
    "    input_length = config.audio_length\n",
    "    \n",
    "    inp = Input(shape=(input_length,1))\n",
    "    x = Convolution1D(16, 9, activation=relu, padding=\"valid\")(inp)\n",
    "    x = Convolution1D(16, 9, activation=relu, padding=\"valid\")(x)\n",
    "    x = MaxPool1D(16)(x)\n",
    "    x = Dropout(rate=0.1)(x)\n",
    "    \n",
    "    x = Convolution1D(32, 3, activation=relu, padding=\"valid\")(x)\n",
    "    x = Convolution1D(32, 3, activation=relu, padding=\"valid\")(x)\n",
    "    x = MaxPool1D(4)(x)\n",
    "    x = Dropout(rate=0.1)(x)\n",
    "    \n",
    "    x = Convolution1D(32, 3, activation=relu, padding=\"valid\")(x)\n",
    "    x = Convolution1D(32, 3, activation=relu, padding=\"valid\")(x)\n",
    "    x = MaxPool1D(4)(x)\n",
    "    x = Dropout(rate=0.1)(x)\n",
    "    \n",
    "    x = Convolution1D(256, 3, activation=relu, padding=\"valid\")(x)\n",
    "    x = Convolution1D(256, 3, activation=relu, padding=\"valid\")(x)\n",
    "    x = GlobalMaxPool1D()(x)\n",
    "    x = Dropout(rate=0.2)(x)\n",
    "\n",
    "    x = Dense(64, activation=relu)(x)\n",
    "    x = Dense(1028, activation=relu)(x)\n",
    "    out = Dense(nclass, activation=softmax)(x)\n",
    "\n",
    "    model = models.Model(inputs=inp, outputs=out)\n",
    "    opt = optimizers.Adam(config.learning_rate)\n",
    "\n",
    "    model.compile(optimizer=opt, loss=losses.categorical_crossentropy, metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training 1D Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = list(train.label.unique())\n",
    "label_idx = {label: i for i, label in enumerate(LABELS)}\n",
    "train.set_index(\"fname\", inplace=True)\n",
    "test.set_index(\"fname\", inplace=True)\n",
    "train[\"label_idx\"] = train.label.apply(lambda x: label_idx[x])\n",
    "if not COMPLETE_RUN:\n",
    "    train = train[:2000]\n",
    "    test = test[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(sampling_rate=16000, audio_duration=2, n_folds=10, learning_rate=0.001)\n",
    "if not COMPLETE_RUN:\n",
    "    config = Config(sampling_rate=100, audio_duration=1, n_folds=2, max_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTION_FOLDER = get_path(\"predictions_1d_conv\")\n",
    "if not os.path.exists(PREDICTION_FOLDER):\n",
    "    os.mkdir(PREDICTION_FOLDER)\n",
    "if os.path.exists('logs/' + PREDICTION_FOLDER):\n",
    "    shutil.rmtree('logs/' + PREDICTION_FOLDER)\n",
    "\n",
    "skf = StratifiedKFold(train.label_idx, n_folds=config.n_folds)\n",
    "\n",
    "for i, (train_split, val_split) in enumerate(skf):\n",
    "    train_set = train.iloc[train_split]\n",
    "    val_set = train.iloc[val_split]\n",
    "    checkpoint = ModelCheckpoint('best_%d.h5'%i, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "    early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5)\n",
    "    tb = TensorBoard(log_dir='./logs/' + PREDICTION_FOLDER + '/fold_%d'%i, write_graph=True)\n",
    "\n",
    "    callbacks_list = [checkpoint, early, tb]\n",
    "    print(\"Fold: \", i)\n",
    "    print(\"#\"*50)\n",
    "    if COMPLETE_RUN:\n",
    "        model = get_1d_conv_model(config)\n",
    "    else:\n",
    "        model = get_1d_dummy_model(config)\n",
    "\n",
    "    train_generator = DataGenerator(config, AUDIO_TRAIN, train_set.index, \n",
    "                                    train_set.label_idx, batch_size=64,\n",
    "                                    preprocessing_fn=audio_norm)\n",
    "    val_generator = DataGenerator(config, AUDIO_TRAIN, val_set.index, \n",
    "                                  val_set.label_idx, batch_size=64,\n",
    "                                  preprocessing_fn=audio_norm)\n",
    "\n",
    "    history = model.fit_generator(train_generator, callbacks=callbacks_list, validation_data=val_generator,\n",
    "                                  epochs=config.max_epochs, use_multiprocessing=True, workers=6, max_queue_size=20)\n",
    "\n",
    "    model.load_weights('best_%d.h5'%i)\n",
    "\n",
    "    # Save train predictions\n",
    "    train_generator = DataGenerator(config, AUDIO_TRAIN, train.index, batch_size=128,\n",
    "                                    preprocessing_fn=audio_norm)\n",
    "    predictions = model.predict_generator(train_generator, use_multiprocessing=True, \n",
    "                                          workers=6, max_queue_size=20, verbose=1)\n",
    "    np.save(PREDICTION_FOLDER + \"/train_predictions_%d.npy\"%i, predictions)\n",
    "\n",
    "    # Save test predictions\n",
    "    test_generator = DataGenerator(config, AUDIO_TEST, test.index, batch_size=128,\n",
    "                                    preprocessing_fn=audio_norm)\n",
    "    predictions = model.predict_generator(test_generator, use_multiprocessing=True, \n",
    "                                          workers=6, max_queue_size=20, verbose=1)\n",
    "    np.save(PREDICTION_FOLDER + \"/test_predictions_%d.npy\"%i, predictions)\n",
    "\n",
    "    # Make a submission file\n",
    "    top_3 = np.array(LABELS)[np.argsort(-predictions, axis=1)[:, :3]]\n",
    "    predicted_labels = [' '.join(list(x)) for x in top_3]\n",
    "    test['label'] = predicted_labels\n",
    "    test[['label']].to_csv(PREDICTION_FOLDER + \"/predictions_%d.csv\"%i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    def __init__(self,\n",
    "                 sampling_rate=16000, audio_duration=2, n_classes=41,\n",
    "                 use_mfcc=False, n_folds=10, learning_rate=0.0001, \n",
    "                 max_epochs=50, n_mfcc=20):\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.audio_duration = audio_duration\n",
    "        self.n_classes = n_classes\n",
    "        self.use_mfcc = use_mfcc\n",
    "        self.n_mfcc = n_mfcc\n",
    "        self.n_folds = n_folds\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_epochs = max_epochs\n",
    "\n",
    "        self.audio_length = self.sampling_rate * self.audio_duration\n",
    "        if self.use_mfcc:\n",
    "            self.dim = (self.n_mfcc, 1 + int(np.floor(self.audio_length/512)), 1)\n",
    "        else:\n",
    "            self.dim = (self.audio_length, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(sampling_rate=44100, audio_duration=2, n_folds=10, \n",
    "                learning_rate=0.001, use_mfcc=True, n_mfcc=40)\n",
    "if not COMPLETE_RUN:\n",
    "    config = Config(sampling_rate=44100, audio_duration=2, n_folds=2, \n",
    "                    max_epochs=1, use_mfcc=True, n_mfcc=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df, config, data_dir):\n",
    "    X = np.empty(shape=(df.shape[0], config.dim[0], config.dim[1], 1))\n",
    "    input_length = config.audio_length\n",
    "    for i, fname in enumerate(df.index):\n",
    "        print(fname)\n",
    "        file_path = data_dir + str(fname)\n",
    "        data, _ = librosa.core.load(file_path, sr=config.sampling_rate, res_type=\"kaiser_fast\")\n",
    "\n",
    "        # Random offset / Padding\n",
    "        if len(data) > input_length:\n",
    "            max_offset = len(data) - input_length\n",
    "            offset = np.random.randint(max_offset)\n",
    "            data = data[offset:(input_length+offset)]\n",
    "        else:\n",
    "            if input_length > len(data):\n",
    "                max_offset = input_length - len(data)\n",
    "                offset = np.random.randint(max_offset)\n",
    "            else:\n",
    "                offset = 0\n",
    "            data = np.pad(data, (offset, input_length - len(data) - offset), \"constant\")\n",
    "\n",
    "        data = librosa.feature.mfcc(data, sr=config.sampling_rate, n_mfcc=config.n_mfcc)\n",
    "        data = np.expand_dims(data, axis=-1)\n",
    "        X[i,] = data\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = prepare_data(train, config, get_path('audio_train'))\n",
    "X_test = prepare_data(test, config, get_path('audio_test'))\n",
    "y_train = to_categorical(train.label_idx, num_classes=config.n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "\n",
    "mean = np.mean(X_train, axis=0)\n",
    "std = np.std(X_train, axis=0)\n",
    "X_train = (X_train - mean)/std\n",
    "X_test = (X_test - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTION_FOLDER = \"predictions_2d_conv\"\n",
    "if not os.path.exists(PREDICTION_FOLDER):\n",
    "    os.mkdir(PREDICTION_FOLDER)\n",
    "if os.path.exists('logs/' + PREDICTION_FOLDER):\n",
    "    shutil.rmtree('logs/' + PREDICTION_FOLDER)\n",
    "\n",
    "skf = StratifiedKFold(train.label_idx, n_folds=config.n_folds)\n",
    "for i, (train_split, val_split) in enumerate(skf):\n",
    "    K.clear_session()\n",
    "    X, y, X_val, y_val = X_train[train_split], y_train[train_split], X_train[val_split], y_train[val_split]\n",
    "    checkpoint = ModelCheckpoint('best_%d.h5'%i, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "    early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5)\n",
    "    tb = TensorBoard(log_dir='./logs/' + PREDICTION_FOLDER + '/fold_%i'%i, write_graph=True)\n",
    "    callbacks_list = [checkpoint, early, tb]\n",
    "    print(\"#\"*50)\n",
    "    print(\"Fold: \", i)\n",
    "    model = get_2d_conv_model(config)\n",
    "    history = model.fit(X, y, validation_data=(X_val, y_val), callbacks=callbacks_list, \n",
    "                        batch_size=64, epochs=config.max_epochs)\n",
    "    model.load_weights('best_%d.h5'%i)\n",
    "\n",
    "    # Save train predictions\n",
    "    predictions = model.predict(X_train, batch_size=64, verbose=1)\n",
    "    np.save(PREDICTION_FOLDER + \"/train_predictions_%d.npy\"%i, predictions)\n",
    "\n",
    "    # Save test predictions\n",
    "    predictions = model.predict(X_test, batch_size=64, verbose=1)\n",
    "    np.save(PREDICTION_FOLDER + \"/test_predictions_%d.npy\"%i, predictions)\n",
    "\n",
    "    # Make a submission file\n",
    "    top_3 = np.array(LABELS)[np.argsort(-predictions, axis=1)[:, :3]]\n",
    "    predicted_labels = [' '.join(list(x)) for x in top_3]\n",
    "    test['label'] = predicted_labels\n",
    "    test[['label']].to_csv(PREDICTION_FOLDER + \"/predictions_%d.csv\"%i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list = []\n",
    "for i in range(10):\n",
    "    pred_list.append(np.load(\"../input/freesound-prediction-data-2d-conv-reduced-lr/test_predictions_%d.npy\"%i))\n",
    "prediction = np.ones_like(pred_list[0])\n",
    "for pred in pred_list:\n",
    "    prediction = prediction*pred\n",
    "prediction = prediction**(1./len(pred_list))\n",
    "# Make a submission file\n",
    "top_3 = np.array(LABELS)[np.argsort(-prediction, axis=1)[:, :3]]\n",
    "predicted_labels = [' '.join(list(x)) for x in top_3]\n",
    "test = pd.read_csv('../input/freesound-audio-tagging/sample_submission.csv')\n",
    "test['label'] = predicted_labels\n",
    "test[['fname', 'label']].to_csv(\"2d_conv_ensembled_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list = []\n",
    "for i in range(10):\n",
    "    pred_list.append(np.load(\"../input/freesound-prediction-data-2d-conv-reduced-lr/test_predictions_%d.npy\"%i))\n",
    "for i in range(10):\n",
    "    pred_list.append(np.load(\"../input/freesound-prediction-file/test_predictions_%d.npy\"%i))\n",
    "prediction = np.ones_like(pred_list[0])\n",
    "for pred in pred_list:\n",
    "    prediction = prediction*pred\n",
    "prediction = prediction**(1./len(pred_list))\n",
    "# Make a submission file\n",
    "top_3 = np.array(LABELS)[np.argsort(-prediction, axis=1)[:, :3]]\n",
    "predicted_labels = [' '.join(list(x)) for x in top_3]\n",
    "test = pd.read_csv('../input/freesound-audio-tagging/sample_submission.csv')\n",
    "test['label'] = predicted_labels\n",
    "test[['fname', 'label']].to_csv(\"1d_2d_ensembled_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
